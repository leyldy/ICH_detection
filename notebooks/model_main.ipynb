{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imperial-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from itertools import islice\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import webdataset as wds\n",
    "\n",
    "from model.baseline_3d_cnn import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "african-asset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "shards_dir = os.path.join(data_dir, 'shards')\n",
    "\n",
    "# Opening JSON file\n",
    "with open('../parameters.json') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ahead-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [os.path.join(shards_dir, it) for it in os.listdir(shards_dir) if it.endswith('.tar')]\n",
    "train_urls = urls[:round(len(urls)*0.6)]\n",
    "val_urls = urls[round(len(urls)*0.6):]\n",
    "\n",
    "train_dataset = (\n",
    "    wds\n",
    "    .WebDataset(train_urls)\n",
    "    .shuffle(parameters['batch_size'])\n",
    "    .decode('torch')\n",
    "    .to_tuple('volumes.pyd', 'labels.pyd', 'studynames.pyd')\n",
    ")\n",
    "loader_train = torch.utils.data.DataLoader(train_dataset.batched(parameters['batch_size']), num_workers=2, batch_size=None)\n",
    "\n",
    "val_dataset = (\n",
    "    wds\n",
    "    .WebDataset(val_urls)\n",
    "    .shuffle(parameters['batch_size'])\n",
    "    .decode('torch')\n",
    "    .to_tuple('volumes.pyd', 'labels.pyd', 'studynames.pyd')\n",
    ")\n",
    "loader_val = torch.utils.data.DataLoader(val_dataset.batched(parameters['batch_size']), num_workers=2, batch_size=None)\n",
    "\n",
    "# for image, target in islice(dataset, 0, 2):\n",
    "#     print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "underlying-arlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "dtype = torch.float\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "thrown-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(loader, model, criterion, iteration, writer):\n",
    "    print('Checking accuracy on validation set')\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        targets_np, scores_np, val_losses = [], [], []\n",
    "        \n",
    "        # Run validation on validation batches\n",
    "        for x, y, z in loader:\n",
    "            # Temporarily add code to unsqueeze #TEMP\n",
    "            x = x.unsqueeze(axis=1)\n",
    "            \n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            scores = model(x)\n",
    "            val_loss = criterion(scores, y)\n",
    "            val_losses.append(val_loss.item())\n",
    "            \n",
    "            scores_np.extend(scores.cpu().numpy())\n",
    "            targets_np.extend(y.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics after running full validation set\n",
    "        scores_np, targets_np = np.array(scores_np), np.array(targets_np)\n",
    "        ind_dict, avg_dict = calculate_metrics(scores_np, targets_np)\n",
    "        \n",
    "        # Save metrics to tensorboard\n",
    "        writer.add_scalar(\"Loss/validation\", np.mean(val_losses), iteration)\n",
    "        writer.add_scalar(\"Micro Accuracy/validation\", avg_dict['accuracy'], iteration)\n",
    "        writer.add_scalars(\"Micro Precision-Recall-F1/validation\", \n",
    "                           {'Precision': avg_dict['precision'], 'Recall': avg_dict['recall'], 'F1': avg_dict['fscore']}, iteration)\n",
    "        \n",
    "        # Print results\n",
    "        print(\"Validation results, iter: {:2d}\".format(iteration))\n",
    "        print(\"Loss: {:.4f}, Micro accuracy: {:.3f}, Micro precision: {:.3f}, Micro recall: {:.3f}, Micro F1: {:.3f}\"\n",
    "              .format(np.mean(val_losses), avg_dict['accuracy'], avg_dict['precision'], avg_dict['recall'], avg_dict['fscore'])\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "honey-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, loader_train, loader_val, writer, epochs=5, device=device, val_every=1):\n",
    "    \"\"\"\n",
    "    Train a model.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    batch_losses = []\n",
    "    total_iter = 0\n",
    "    for e in range(epochs):\n",
    "        print(\"************EPOCH: {:2d} ***************\".format(e))\n",
    "        for t, (x, y, z) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            \n",
    "            # Temporarily add code to unsqueeze #TEMP\n",
    "            x = x.unsqueeze(axis=1)\n",
    "            \n",
    "            x = x.to(device=device)  # move to device, e.g. GPU\n",
    "            x = x.type(torch.cuda.FloatTensor)\n",
    "\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = criterion(scores, y)\n",
    "            curr_batchloss = loss.item()\n",
    "            batch_losses.append(curr_batchloss)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate train metrics\n",
    "            ind_dict, avg_dict = calculate_metrics(scores.detach().cpu().numpy(), y.detach().cpu().numpy(), threshold=0.5)\n",
    "            \n",
    "            # Write train metrics to tensorboard (could move this when we run validation step..?)\n",
    "            writer.add_scalar(\"Loss/train\", curr_batchloss, total_iter+t)\n",
    "            writer.add_scalar(\"Micro Accuracy/train\", avg_dict['accuracy'], total_iter+t)\n",
    "            writer.add_scalars(\"Micro Precision-Recall-F1/train\", \n",
    "                               {'Precision': avg_dict['precision'], 'Recall': avg_dict['recall'], 'F1': avg_dict['fscore']}, total_iter+t)\n",
    "            \n",
    "            # Run validation step\n",
    "            if t % val_every == 0:\n",
    "                print('Iteration %d, train loss = %.4f' % (t, curr_batchloss))\n",
    "                validate_model(loader_val, model, criterion, total_iter+t, writer)\n",
    "                print()\n",
    "                writer.flush()\n",
    "        total_iter += t+1\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "smooth-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = baseline_3DCNN(in_num_ch=1)\n",
    "\n",
    "currtime = datetime.now(tz=pytz.utc).astimezone(timezone('US/Pacific')).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "writer = SummaryWriter(log_dir=os.path.join('../runs', currtime))\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ordinary-transformation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "identical-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************EPOCH:  0 ***************\n",
      "Iteration 0, loss = 0.7341\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results, iter:  0\n",
      "Loss: 0.6734, Micro accuracy: 0.681, Micro precision: 0.152, Micro recall: 0.189, Micro F1: 0.169\n",
      "\n",
      "Iteration 1, loss = 1.9795\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results, iter:  1\n",
      "Loss: 0.6924, Micro accuracy: 0.421, Micro precision: 0.172, Micro recall: 0.622, Micro F1: 0.269\n",
      "\n",
      "************EPOCH:  1 ***************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 1.2643\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results, iter:  2\n",
      "Loss: 0.7243, Micro accuracy: 0.477, Micro precision: 0.142, Micro recall: 0.405, Micro F1: 0.210\n",
      "\n",
      "Iteration 1, loss = 1.1966\n",
      "Checking accuracy on validation set\n",
      "Validation results, iter:  3\n",
      "Loss: 0.8648, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n",
      "************EPOCH:  2 ***************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.7779\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results, iter:  4\n",
      "Loss: 1.1169, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n",
      "Iteration 1, loss = 0.8344\n",
      "Checking accuracy on validation set\n",
      "Validation results, iter:  5\n",
      "Loss: 1.4659, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n",
      "************EPOCH:  3 ***************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.6980\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results, iter:  6\n",
      "Loss: 1.8011, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n",
      "Iteration 1, loss = 0.6195\n",
      "Checking accuracy on validation set\n",
      "Validation results, iter:  7\n",
      "Loss: 2.1176, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n",
      "************EPOCH:  4 ***************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.6164\n",
      "Checking accuracy on validation set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation results, iter:  8\n",
      "Loss: 2.4588, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n",
      "Iteration 1, loss = 0.6044\n",
      "Checking accuracy on validation set\n",
      "Validation results, iter:  9\n",
      "Loss: 2.6201, Micro accuracy: 0.458, Micro precision: 0.130, Micro recall: 0.378, Micro F1: 0.193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, loader_train, loader_val, writer, epochs=5, device=device, val_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-prince",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
