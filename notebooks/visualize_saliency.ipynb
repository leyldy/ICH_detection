{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3xiDs0EGNQl"
   },
   "source": [
    "## Visualize image-specific class saliency with backpropagation\n",
    "\n",
    "---\n",
    "\n",
    "The gradients obtained can be used to visualise an image-specific class saliency map, which can gives some intuition on regions within the input image that contribute the most (and least) to the corresponding output.\n",
    "\n",
    "More details on saliency maps: [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/pdf/1312.6034.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCTTe6LrGNQo"
   },
   "source": [
    "### 0. Set up (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622616577358,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "iL2cM5yQGNQo",
    "outputId": "3b6ce1b5-d387-475b-ebfe-83c663ea8d1d"
   },
   "outputs": [],
   "source": [
    "# # Install flashtorch if you don't have it\n",
    "\n",
    "# !pip install webdataset\n",
    "\n",
    "\n",
    "# # This mounts your Google Drive to th?e Colab VM.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# # assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
    "# FOLDERNAME = 'Courses/Spring 2021/CS 231N/cs231n_final_proj/netviz'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# # Now that we've mounted your Drive, this ensures that\n",
    "# # the Python interpreter of the Colab VM can load\n",
    "# # python files from within it.\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# os.chdir('/content/drive/My Drive/{}'.format(FOLDERNAME+'/notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 13222,
     "status": "ok",
     "timestamp": 1622616592425,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "lENR9nxyGNQp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import webdataset as wds\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import psutil\n",
    "\n",
    "\n",
    "from model.baseline_3d_cnn import *\n",
    "from model.selfattn_3d_cnn import *\n",
    "from model.resattn_3d_cnn import *\n",
    "from utils.saliency_map import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1622616593042,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "2h1g4znhGNQp",
    "outputId": "9ed8032a-ae16-463d-cd3d-6e3957706b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4, 'shard_size': 16}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "shards_dir = os.path.join(data_dir, 'shards_new')\n",
    "\n",
    "# Opening JSON file\n",
    "with open('../parameters.json') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "batch_size = parameters['batch_size']\n",
    "shard_size = parameters['shard_size']\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1622616593421,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "yYroJud1GNQq",
    "outputId": "b9faa13f-5c13-46a8-e847-3eb4d680393b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/shards_new/shard-000076.tar', '../data/shards_new/shard-000003.tar', '../data/shards_new/shard-000081.tar', '../data/shards_new/shard-000065.tar', '../data/shards_new/shard-000051.tar', '../data/shards_new/shard-000044.tar', '../data/shards_new/shard-000037.tar', '../data/shards_new/shard-000095.tar', '../data/shards_new/shard-000084.tar', '../data/shards_new/shard-000090.tar', '../data/shards_new/shard-000040.tar', '../data/shards_new/shard-000062.tar', '../data/shards_new/shard-000022.tar', '../data/shards_new/shard-000078.tar', '../data/shards_new/shard-000045.tar', '../data/shards_new/shard-000023.tar', '../data/shards_new/shard-000058.tar', '../data/shards_new/shard-000063.tar', '../data/shards_new/shard-000086.tar', '../data/shards_new/shard-000071.tar', '../data/shards_new/shard-000067.tar', '../data/shards_new/shard-000013.tar', '../data/shards_new/shard-000034.tar', '../data/shards_new/shard-000072.tar', '../data/shards_new/shard-000082.tar', '../data/shards_new/shard-000070.tar', '../data/shards_new/shard-000009.tar', '../data/shards_new/shard-000012.tar', '../data/shards_new/shard-000010.tar', '../data/shards_new/shard-000032.tar', '../data/shards_new/shard-000036.tar', '../data/shards_new/shard-000061.tar', '../data/shards_new/shard-000048.tar', '../data/shards_new/shard-000031.tar', '../data/shards_new/shard-000055.tar', '../data/shards_new/shard-000046.tar', '../data/shards_new/shard-000080.tar', '../data/shards_new/shard-000041.tar', '../data/shards_new/shard-000050.tar', '../data/shards_new/shard-000085.tar', '../data/shards_new/shard-000017.tar', '../data/shards_new/shard-000083.tar', '../data/shards_new/shard-000004.tar', '../data/shards_new/shard-000060.tar', '../data/shards_new/shard-000057.tar', '../data/shards_new/shard-000069.tar', '../data/shards_new/shard-000006.tar', '../data/shards_new/shard-000020.tar', '../data/shards_new/shard-000042.tar', '../data/shards_new/shard-000087.tar', '../data/shards_new/shard-000035.tar', '../data/shards_new/shard-000047.tar', '../data/shards_new/shard-000089.tar', '../data/shards_new/shard-000059.tar', '../data/shards_new/shard-000002.tar', '../data/shards_new/shard-000056.tar', '../data/shards_new/shard-000096.tar', '../data/shards_new/shard-000025.tar', '../data/shards_new/shard-000018.tar', '../data/shards_new/shard-000033.tar', '../data/shards_new/shard-000019.tar', '../data/shards_new/shard-000079.tar', '../data/shards_new/shard-000014.tar', '../data/shards_new/shard-000039.tar', '../data/shards_new/shard-000075.tar', '../data/shards_new/shard-000066.tar', '../data/shards_new/shard-000094.tar', '../data/shards_new/shard-000077.tar', '../data/shards_new/shard-000011.tar', '../data/shards_new/shard-000028.tar', '../data/shards_new/shard-000091.tar', '../data/shards_new/shard-000064.tar', '../data/shards_new/shard-000008.tar', '../data/shards_new/shard-000030.tar', '../data/shards_new/shard-000007.tar', '../data/shards_new/shard-000043.tar', '../data/shards_new/shard-000005.tar', '../data/shards_new/shard-000092.tar', '../data/shards_new/shard-000024.tar', '../data/shards_new/shard-000053.tar', '../data/shards_new/shard-000029.tar', '../data/shards_new/shard-000074.tar', '../data/shards_new/shard-000073.tar', '../data/shards_new/shard-000001.tar', '../data/shards_new/shard-000038.tar', '../data/shards_new/shard-000027.tar', '../data/shards_new/shard-000068.tar', '../data/shards_new/shard-000052.tar', '../data/shards_new/shard-000088.tar', '../data/shards_new/shard-000093.tar', '../data/shards_new/shard-000021.tar', '../data/shards_new/shard-000015.tar', '../data/shards_new/shard-000016.tar', '../data/shards_new/shard-000054.tar', '../data/shards_new/shard-000049.tar', '../data/shards_new/shard-000026.tar']\n"
     ]
    }
   ],
   "source": [
    "urls = [os.path.join(shards_dir, it) for it in os.listdir(shards_dir) if it.endswith('.tar')]\n",
    "wds_len = len(urls)*shard_size//batch_size\n",
    "\n",
    "image_dataset = (\n",
    "    wds\n",
    "    .WebDataset(urls, length=wds_len)\n",
    "    .shuffle(shard_size)\n",
    "    .decode('torch')\n",
    "    .to_tuple('volumes.pyd', 'labels.pyd', 'studynames.pyd')\n",
    "    .batched(batch_size)\n",
    "#     .map_tuple(pre_transforms, identity, identity)\n",
    ")\n",
    "\n",
    "\n",
    "image_loader = torch.utils.data.DataLoader(image_dataset, num_workers=0, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwUtipxTGNQq"
   },
   "source": [
    "### 1. Load an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622616593423,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "iIdnH_AVGNQr"
   },
   "outputs": [],
   "source": [
    "# patient_num = 1\n",
    "\n",
    "# for t, (x, y, z) in enumerate(image_loader):\n",
    "#     if t > 0:\n",
    "#         break\n",
    "#     img_df = x[patient_num, :, :, :].detach().numpy()\n",
    "#     img_y = y[patient_num, :]\n",
    "# del x # For now for memory reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622616593424,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "NAfZ9dTCGNQr"
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(5,8, figsize=(15, 6))\n",
    "# axs = axs.ravel()\n",
    "# for i in range(40):\n",
    "#     axs[i].imshow(img_df[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtSeabbvGNQs"
   },
   "source": [
    "### 2. Load a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join('..', 'runs', 'baseline')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'baseline_final_model.pt') # COLAB\n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "ckpt_model = baseline_3DCNN(in_num_ch=1)\n",
    "ckpt_model.load_state_dict(ckpt)\n",
    "\n",
    "plot_dir = os.path.join('..', 'net_visualization', 'baseline')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_dir = os.path.join('..', 'runs', 'experiment_att')\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'experiment_final_model.pt') \n",
    "# ckpt = torch.load(ckpt_path)\n",
    "\n",
    "# ckpt_model = selfattn_3DCNN(in_num_ch=1)\n",
    "# ckpt_model.load_state_dict(ckpt)\n",
    "\n",
    "# plot_dir = os.path.join('..', 'net_visualization', 'experiment_att')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ckpt_dir = os.path.join('..', 'runs', 'experiment_res')\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'experimentres_final_model.pt') \n",
    "# ckpt = torch.load(ckpt_path)\n",
    "\n",
    "# ckpt_model = resattn_3DCNN(in_num_ch=1)\n",
    "# ckpt_model.load_state_dict(ckpt)\n",
    "\n",
    "# plot_dir = os.path.join('..', 'net_visualization', 'experiment_res')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8Vb5EQqMKvc"
   },
   "source": [
    "### 3. Generate saliency map statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1622616622945,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "_Bw8x2W9iTpS",
    "outputId": "eb09eb16-c224-4e0c-bba7-35fbb74a0eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "#     dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61206"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 23975,
     "status": "error",
     "timestamp": 1622618523806,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "SpD_zYtuMMxA",
    "outputId": "8ca56328-b912-4bd4-8c69-af0e7c1bc409"
   },
   "outputs": [],
   "source": [
    "full_sal_df = pd.DataFrame()\n",
    "\n",
    "with tqdm(image_loader, unit=\"batch\") as tepoch:\n",
    "    for t, (x, y, z) in enumerate(tepoch): # For each batch\n",
    "        gc.collect()\n",
    "            \n",
    "        tepoch.set_description(\"Batch %d\" % t)\n",
    "        \n",
    "        # Some default constants\n",
    "        N = y.shape[0]\n",
    "        ICHD = y.shape[1]\n",
    "\n",
    "        # Compute saliency and rank of slices\n",
    "        saliency = compute_saliency_maps(x, y, ckpt_model, device) # (ICH_types, N, D, H, W)\n",
    "        saliency_rank = rank_saliency_slices(saliency) #(ICH_types, N, D)\n",
    "        \n",
    "        # Compute whether prediction was correct or not\n",
    "        ckpt_model = ckpt_model.to(device)\n",
    "        ckpt_model.eval()\n",
    "        \n",
    "        preds = (torch.sigmoid(ckpt_model(x.to(device, dtype=torch.float))) >= 0.5).long()\n",
    "        corr_bool = (y == preds.cpu()).long() # N X 6\n",
    "\n",
    "        # Save plot of saliency map in each patient directory\n",
    "        # Only do up to 10 batches for plotting (40 patients)\n",
    "#         if t < 10:\n",
    "#             for p_index in range(N):\n",
    "#                 patient_id = z[p_index].item()\n",
    "#                 patient_ichs_ind = y[p_index, :].nonzero(as_tuple=True)[0] # Only ICH nums which patients have\n",
    "#                 if len(patient_ichs_ind) == 0: # Skip patient if patient doesn't have any ICH\n",
    "#                     continue \n",
    "#                 patient_corr = corr_bool[p_index, :]\n",
    "\n",
    "#                 # Make plot directory for patient\n",
    "#                 dir_nm = '_'.join([patient_id, \n",
    "#                                    'numICHs', str(len(patient_ichs_ind)), \n",
    "#                                    'numCorr', str(patient_corr[patient_ichs_ind].sum().item())\n",
    "#                                   ])\n",
    "#                 patient_dir = os.path.join(plot_dir, dir_nm)\n",
    "#                 if not os.path.exists(patient_dir):\n",
    "#                     os.mkdir(patient_dir)\n",
    "\n",
    "#                 for ich_num in patient_ichs_ind.cpu().numpy():\n",
    "#                     sal_plot = plot_saliency_maps(x, saliency, ich_num=ich_num, patient_id=p_index, \n",
    "#                                                   d_range=np.arange(0,40), num_rows = 2*8, num_cols = 5)\n",
    "#                     sal_plot.savefig(os.path.join(patient_dir, '_'.join(['ICHNum', str(ich_num), 'Corr', str(patient_corr[ich_num].item())])))\n",
    "#                     # Clear the current axes.\n",
    "#                     plt.cla() \n",
    "#                     # Clear the current figure.\n",
    "#                     plt.clf() \n",
    "#                     sal_plot.clear()\n",
    "#                     plt.close('all')\n",
    "#                     del sal_plot\n",
    "                \n",
    "        # Convert to pandas df to save general information (patient ID, num of ICH class, pred corr or not (per num ICH class), sal rank per ICH class)\n",
    "        save_df = pd.DataFrame(saliency_rank.detach().cpu().numpy().reshape(ICHD*N, -1)) # (ICH_types*N, D)\n",
    "        save_df.columns = ['rank_' + str(rk) for rk in save_df.columns]\n",
    "\n",
    "        save_df['patient_id'] = z.repeat(ICHD)\n",
    "        save_df['ICH_num'] = np.tile(np.arange(0, ICHD), N)\n",
    "        save_df['ICH_true'] = y.numpy().astype(int).reshape(-1)\n",
    "        save_df['ICH_pred'] = preds.detach().cpu().numpy().astype(int).reshape(-1)\n",
    "        save_df['corr_pred'] = corr_bool.detach().numpy().reshape(-1)\n",
    "        save_df = save_df[save_df.columns.tolist()[-5:] + save_df.columns.tolist()[:-5]]\n",
    "\n",
    "        full_sal_df = pd.concat([full_sal_df, save_df], axis=0)\n",
    "        \n",
    "        # Delete to free up memory?\n",
    "        del saliency\n",
    "        del saliency_rank\n",
    "        del x\n",
    "        \n",
    "        print('CUDA:', torch.cuda.memory_allocated())\n",
    "        print('RAM:', psutil.virtual_memory().percent)\n",
    "\n",
    "full_sal_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sal_df.to_csv(os.path.join(plot_dir, 'saliency_statistics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9216, 45)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_sal_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots for first 2 batches' patients, across different models, and top 10 slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/shards_new/shard-000076.tar', '../data/shards_new/shard-000003.tar']\n"
     ]
    }
   ],
   "source": [
    "urls = [os.path.join(shards_dir, it) for it in os.listdir(shards_dir) if it.endswith('.tar')]\n",
    "urls = urls[:2]\n",
    "wds_len = len(urls)*shard_size//batch_size\n",
    "print(urls)\n",
    "image_dataset = (\n",
    "    wds\n",
    "    .WebDataset(urls, length=wds_len)\n",
    "#     .shuffle(shard_size)\n",
    "    .decode('torch')\n",
    "    .to_tuple('volumes.pyd', 'labels.pyd', 'studynames.pyd')\n",
    "    .batched(batch_size)\n",
    "#     .map_tuple(pre_transforms, identity, identity)\n",
    ")\n",
    "\n",
    "\n",
    "image_loader = torch.utils.data.DataLoader(image_dataset, num_workers=0, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ckpt_dir = os.path.join('..', 'runs', 'baseline')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'baseline_final_model.pt') # COLAB\n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "ckpt_model = baseline_3DCNN(in_num_ch=1)\n",
    "ckpt_model.load_state_dict(ckpt)\n",
    "\n",
    "models.append(ckpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join('..', 'runs', 'experiment_att')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'experiment_final_model.pt') \n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "ckpt_model = selfattn_3DCNN(in_num_ch=1)\n",
    "ckpt_model.load_state_dict(ckpt)\n",
    "\n",
    "models.append(ckpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join('..', 'runs', 'experiment_res')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'experimentres_final_model.pt') \n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "ckpt_model = resattn_3DCNN(in_num_ch=1)\n",
    "ckpt_model.load_state_dict(ckpt)\n",
    "\n",
    "models.append(ckpt_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['baseline', 'experiment_att', 'experiment_res']\n",
    "plot_dir = os.path.join('..', 'net_visualization', 'select_patients')\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:33<10:55, 93.71s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [03:59<12:27, 124.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 38.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [05:02<08:01, 96.20s/batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 40.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [05:03<03:55, 58.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 40.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [06:32<03:28, 69.56s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 42.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [07:47<02:22, 71.30s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 44.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [09:20<01:18, 78.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 47.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [10:16<00:00, 77.05s/batch]\n",
      "  0%|          | 0/8 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 108878336\n",
      "RAM: 47.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:32<10:44, 92.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 50.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:46<08:10, 81.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 52.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [04:15<07:04, 84.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 55.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [05:09<04:51, 72.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 57.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [06:40<03:58, 79.40s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 59.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [09:02<03:21, 100.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 64.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [10:07<01:29, 89.00s/batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 66.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [10:10<00:00, 76.31s/batch]\n",
      "  0%|          | 0/8 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 216417280\n",
      "RAM: 65.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [01:29<10:25, 89.36s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 68.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [02:42<07:57, 79.58s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 70.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [04:11<07:01, 84.28s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 72.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [05:07<04:51, 72.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 74.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [06:38<03:58, 79.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 77.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [09:00<03:21, 100.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 81.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [10:05<01:28, 88.91s/batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 83.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [10:08<00:00, 76.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 428837376\n",
      "RAM: 83.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, mod in enumerate(zip(model_names, models)):\n",
    "    with tqdm(image_loader, unit=\"batch\") as tmod:\n",
    "        for t, (x, y, z) in enumerate(tmod): # For each batch\n",
    "            gc.collect()\n",
    "            tmod.set_description(\"Model %d\" % i)\n",
    "\n",
    "            # Some default constants\n",
    "            N = y.shape[0]\n",
    "            ICHD = y.shape[1]\n",
    "            \n",
    "            modname = mod[0]\n",
    "            ckpt_model = mod[1]\n",
    "                        \n",
    "            # Compute saliency and rank of slices\n",
    "            saliency = compute_saliency_maps(x, y, ckpt_model, device) # (ICH_types, N, D, H, W)\n",
    "            saliency_rank = rank_saliency_slices(saliency) #(ICH_types, N, D)\n",
    "\n",
    "            # Compute whether prediction was correct or not\n",
    "            ckpt_model = ckpt_model.to(device)\n",
    "            ckpt_model.eval()\n",
    "\n",
    "            preds = (torch.sigmoid(ckpt_model(x.to(device, dtype=torch.float))) >= 0.5).long()\n",
    "            corr_bool = (y == preds.cpu()).long() # N X 6\n",
    "\n",
    "            # Save plot of saliency map in each patient directory\n",
    "            for p_index in range(N):\n",
    "                patient_id = z[p_index].item()\n",
    "                patient_ichs_ind = y[p_index, :].nonzero(as_tuple=True)[0] # Only ICH nums which patients have\n",
    "                if len(patient_ichs_ind) == 0: # Skip patient if patient doesn't have any ICH\n",
    "                    continue \n",
    "                patient_corr = corr_bool[p_index, :]\n",
    "\n",
    "                # Make plot directory for patient\n",
    "                patient_dir = os.path.join(plot_dir, patient_id)\n",
    "                if not os.path.exists(patient_dir):\n",
    "                    os.mkdir(patient_dir)\n",
    "                \n",
    "                # Make directory for model within that patient\n",
    "                dir_nm = '_'.join([modname, \n",
    "                                   'numICHs', str(len(patient_ichs_ind)), \n",
    "                                   'numCorr', str(patient_corr[patient_ichs_ind].sum().item())\n",
    "                                  ])\n",
    "                mod_dir = os.path.join(patient_dir, dir_nm)\n",
    "                if not os.path.exists(mod_dir):\n",
    "                    os.mkdir(mod_dir)\n",
    "\n",
    "                # For each different ICH subtype that the patient has\n",
    "                for ich_num in patient_ichs_ind.cpu().numpy():\n",
    "                    # Generate top 10 slices for that ICH type, patient\n",
    "                    sal_plot = plot_saliency_maps(x, saliency, ich_num=ich_num, patient_id=p_index, \n",
    "                                                  d_range=saliency_rank[ich_num, p_index, :10].detach().cpu().numpy(),\n",
    "                                                  num_rows=4, num_cols=5, figsize=(14,9)\n",
    "                                                 ) \n",
    "                    top10_dir = os.path.join(\n",
    "                        mod_dir,\n",
    "                        '_'.join(['ICHNum', str(ich_num), 'Corr', str(patient_corr[ich_num].item()), 'top10'])\n",
    "                    )\n",
    "                    sal_plot.savefig(top10_dir)\n",
    "                    # Clear the current axes.\n",
    "                    plt.cla() \n",
    "                    # Clear the current figure.\n",
    "                    plt.clf() \n",
    "                    sal_plot.clear()\n",
    "                    plt.close('all')\n",
    "                    del sal_plot\n",
    "                    \n",
    "                    # Generate full slices for each patient\n",
    "                    sal_plot = plot_saliency_maps(x, saliency, ich_num=ich_num, patient_id=p_index, \n",
    "                                                  d_range=np.arange(0,40),\n",
    "                                                  num_rows=16, num_cols=5, figsize=(20,40)\n",
    "                                                 ) \n",
    "                    full_dir = os.path.join(\n",
    "                        mod_dir,\n",
    "                        '_'.join(['ICHNum', str(ich_num), 'Corr', str(patient_corr[ich_num].item()), 'full'])\n",
    "                    )\n",
    "                    sal_plot.savefig(full_dir)\n",
    "                    # Clear the current axes.\n",
    "                    plt.cla() \n",
    "                    # Clear the current figure.\n",
    "                    plt.clf() \n",
    "                    sal_plot.clear()\n",
    "                    plt.close('all')\n",
    "                    del sal_plot\n",
    "\n",
    "            # Delete to free up memory?\n",
    "            del saliency\n",
    "            del saliency_rank\n",
    "            del x\n",
    "\n",
    "#             print('CUDA:', torch.cuda.memory_allocated())\n",
    "#             print('RAM:', psutil.virtual_memory().percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SoX3BJh3q05"
   },
   "outputs": [],
   "source": [
    "# # Getting which patients have non ICH types\n",
    "# patient_keys, nonzero_dims = y.nonzero(as_tuple=True)\n",
    "# patient_keys = list(patient_keys.numpy())\n",
    "# nonzero_dims = list(nonzero_dims.numpy())\n",
    "\n",
    "# nonzero_dict = {}\n",
    "# for i in range(len(patient_keys)):\n",
    "#     nonzero_dict[patient_keys[i]] = nonzero_dict.get(patient_keys[i], []) + [nonzero_dims[i]]\n",
    "# nonzero_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of important CT slices over all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_stat_dir = os.path.join('..', 'net_visualization')\n",
    "model_names = ['baseline', 'experiment_att', 'experiment_res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modnm in model_names:\n",
    "    sal_stat = pd.read_csv(os.path.join(sal_stat_dir, modnm, 'saliency_statistics.csv'))\n",
    "#     print(sal_stat.shape)\n",
    "\n",
    "    # Weird duplicates, shouldn't exist..\n",
    "    sal_stat = sal_stat.drop_duplicates(['patient_id', 'ICH_num'])\n",
    "#     print(sal_stat.shape)\n",
    "\n",
    "    # Restrict to only cases when correct prediction was made\n",
    "    sal_stat = sal_stat.loc[sal_stat['corr_pred']==1]\n",
    "#     print(sal_stat.shape)\n",
    "\n",
    "    # Also restrict to only cases when there actually was an ICH (bc of how we defined saliency)\n",
    "    sal_stat = sal_stat.loc[sal_stat['ICH_true']==1]\n",
    "#     print(sal_stat.shape)\n",
    "\n",
    "    sal_stat_l = sal_stat.melt(id_vars=sal_stat.columns[:5], var_name='Rank', value_name='slice')\n",
    "    sal_stat_l['Rank'] = sal_stat_l['Rank'].str.replace('rank_', '').astype(int) + 1\n",
    "    sal_avgrank = (\n",
    "        sal_stat_l\n",
    "        .groupby(['ICH_num', 'slice'])['Rank']\n",
    "        .mean()\n",
    "        .reset_index(name=\"avg_rank\")\n",
    "        .sort_values(['ICH_num', 'avg_rank'])\n",
    "    )\n",
    "    sal_avgrank['ICH_num_rank'] = sal_avgrank.groupby(['ICH_num'])['avg_rank'].rank()\n",
    "\n",
    "    sal_avg_w = sal_avgrank.pivot(index='slice', columns=['ICH_num'], values='ICH_num_rank')\n",
    "    sal_avg_w.columns.name = ''\n",
    "    sal_avg_w.reset_index(inplace=True)\n",
    "    sal_avg_w.columns = ['ICH_' + str(s) if s != 'slice' else s for s in sal_avg_w.columns]\n",
    "    sal_avg_w['avg_rank'] = sal_avg_w.iloc[:, 1:].mean(axis=1)\n",
    "    sal_avg_w.sort_values('avg_rank', ascending=True, inplace=True)\n",
    "    sal_avg_w.to_csv(os.path.join(sal_stat_dir, modnm, 'saliency_ranks.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_stat = pd.read_csv(os.path.join(sal_stat_dir, modnm, 'saliency_statistics.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEMP, just to generate slices 31-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_model = models[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = '../net_visualization/tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 0:  12%|█▎        | 1/8 [00:13<01:33, 13.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 1435478016\n",
      "RAM: 76.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 0:  12%|█▎        | 1/8 [00:15<01:46, 15.16s/batch]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tqdm(image_loader, unit=\"batch\") as tepoch:\n",
    "    for t, (x, y, z) in enumerate(tepoch): # For each batch\n",
    "        if t > 0:\n",
    "            break\n",
    "        gc.collect()\n",
    "            \n",
    "        tepoch.set_description(\"Batch %d\" % t)\n",
    "        \n",
    "        # Some default constants\n",
    "        N = y.shape[0]\n",
    "        ICHD = y.shape[1]\n",
    "\n",
    "        # Compute saliency and rank of slices\n",
    "        saliency = compute_saliency_maps(x, y, ckpt_model, device) # (ICH_types, N, D, H, W)\n",
    "        saliency_rank = rank_saliency_slices(saliency) #(ICH_types, N, D)\n",
    "        \n",
    "        # Compute whether prediction was correct or not\n",
    "        ckpt_model = ckpt_model.to(device)\n",
    "        ckpt_model.eval()\n",
    "        \n",
    "        preds = (torch.sigmoid(ckpt_model(x.to(device, dtype=torch.float))) >= 0.5).long()\n",
    "        corr_bool = (y == preds.cpu()).long() # N X 6\n",
    "\n",
    "        # Save plot of saliency map in each patient directory\n",
    "        # Only do up to 10 batches for plotting (40 patients)\n",
    "        if t < 10:\n",
    "            for p_index in range(N):\n",
    "                patient_id = z[p_index].item()\n",
    "                patient_ichs_ind = y[p_index, :].nonzero(as_tuple=True)[0] # Only ICH nums which patients have\n",
    "                if len(patient_ichs_ind) == 0: # Skip patient if patient doesn't have any ICH\n",
    "                    continue \n",
    "                patient_corr = corr_bool[p_index, :]\n",
    "\n",
    "                # Make plot directory for patient\n",
    "                dir_nm = '_'.join([patient_id, \n",
    "                                   'numICHs', str(len(patient_ichs_ind)), \n",
    "                                   'numCorr', str(patient_corr[patient_ichs_ind].sum().item())\n",
    "                                  ])\n",
    "                patient_dir = os.path.join(plot_dir, dir_nm)\n",
    "                if not os.path.exists(patient_dir):\n",
    "                    os.mkdir(patient_dir)\n",
    "\n",
    "                for ich_num in patient_ichs_ind.cpu().numpy():\n",
    "                    sal_plot = plot_saliency_maps(x, saliency, ich_num=ich_num, patient_id=p_index, \n",
    "                                                  d_range=[31,30,29,28,27,25], num_rows = 2, num_cols = 6, figsize=(12,5))\n",
    "                    sal_plot.savefig(os.path.join(patient_dir, '_'.join(['ICHNum', str(ich_num), 'Corr', str(patient_corr[ich_num].item())])))\n",
    "                    # Clear the current axes.\n",
    "                    plt.cla() \n",
    "                    # Clear the current figure.\n",
    "                    plt.clf() \n",
    "                    sal_plot.clear()\n",
    "                    plt.close('all')\n",
    "                    del sal_plot\n",
    "        \n",
    "        print('CUDA:', torch.cuda.memory_allocated())\n",
    "        print('RAM:', psutil.virtual_memory().percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "visualize_saliency_with_backprop.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
