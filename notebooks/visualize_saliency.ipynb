{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3xiDs0EGNQl"
   },
   "source": [
    "## Visualize image-specific class saliency with backpropagation\n",
    "\n",
    "---\n",
    "\n",
    "The gradients obtained can be used to visualise an image-specific class saliency map, which can gives some intuition on regions within the input image that contribute the most (and least) to the corresponding output.\n",
    "\n",
    "More details on saliency maps: [Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps](https://arxiv.org/pdf/1312.6034.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCTTe6LrGNQo"
   },
   "source": [
    "### 0. Set up (Colab only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622616577358,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "iL2cM5yQGNQo",
    "outputId": "3b6ce1b5-d387-475b-ebfe-83c663ea8d1d"
   },
   "outputs": [],
   "source": [
    "# # Install flashtorch if you don't have it\n",
    "\n",
    "# !pip install webdataset\n",
    "\n",
    "\n",
    "# # This mounts your Google Drive to the Colab VM.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# # assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
    "# FOLDERNAME = 'Courses/Spring 2021/CS 231N/cs231n_final_proj/netviz'\n",
    "# assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# # Now that we've mounted your Drive, this ensures that\n",
    "# # the Python interpreter of the Colab VM can load\n",
    "# # python files from within it.\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# os.chdir('/content/drive/My Drive/{}'.format(FOLDERNAME+'/notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 13222,
     "status": "ok",
     "timestamp": 1622616592425,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "lENR9nxyGNQp"
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import json\n",
    "import webdataset as wds\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.baseline_3d_cnn import *\n",
    "from utils.saliency_map import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1622616593042,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "2h1g4znhGNQp",
    "outputId": "9ed8032a-ae16-463d-cd3d-6e3957706b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 4, 'shard_size': 16}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "shards_dir = os.path.join(data_dir, 'shards_new')\n",
    "\n",
    "# Opening JSON file\n",
    "with open('../parameters.json') as json_file:\n",
    "    parameters = json.load(json_file)\n",
    "\n",
    "batch_size = parameters['batch_size']\n",
    "shard_size = parameters['shard_size']\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1622616593421,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "yYroJud1GNQq",
    "outputId": "b9faa13f-5c13-46a8-e847-3eb4d680393b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/shards_new/shard-000076.tar', '../data/shards_new/shard-000003.tar', '../data/shards_new/shard-000081.tar', '../data/shards_new/shard-000065.tar', '../data/shards_new/shard-000051.tar', '../data/shards_new/shard-000044.tar', '../data/shards_new/shard-000037.tar', '../data/shards_new/shard-000095.tar', '../data/shards_new/shard-000084.tar', '../data/shards_new/shard-000090.tar', '../data/shards_new/shard-000040.tar', '../data/shards_new/shard-000062.tar', '../data/shards_new/shard-000022.tar', '../data/shards_new/shard-000078.tar', '../data/shards_new/shard-000045.tar', '../data/shards_new/shard-000023.tar', '../data/shards_new/shard-000058.tar', '../data/shards_new/shard-000063.tar', '../data/shards_new/shard-000086.tar', '../data/shards_new/shard-000071.tar', '../data/shards_new/shard-000067.tar', '../data/shards_new/shard-000013.tar', '../data/shards_new/shard-000034.tar', '../data/shards_new/shard-000072.tar', '../data/shards_new/shard-000082.tar', '../data/shards_new/shard-000070.tar', '../data/shards_new/shard-000009.tar', '../data/shards_new/shard-000012.tar', '../data/shards_new/shard-000010.tar', '../data/shards_new/shard-000032.tar', '../data/shards_new/shard-000036.tar', '../data/shards_new/shard-000061.tar', '../data/shards_new/shard-000048.tar', '../data/shards_new/shard-000031.tar', '../data/shards_new/shard-000055.tar', '../data/shards_new/shard-000046.tar', '../data/shards_new/shard-000080.tar', '../data/shards_new/shard-000041.tar', '../data/shards_new/shard-000050.tar', '../data/shards_new/shard-000085.tar', '../data/shards_new/shard-000017.tar', '../data/shards_new/shard-000083.tar', '../data/shards_new/shard-000004.tar', '../data/shards_new/shard-000060.tar', '../data/shards_new/shard-000057.tar', '../data/shards_new/shard-000069.tar', '../data/shards_new/shard-000006.tar', '../data/shards_new/shard-000020.tar', '../data/shards_new/shard-000042.tar', '../data/shards_new/shard-000087.tar', '../data/shards_new/shard-000035.tar', '../data/shards_new/shard-000047.tar', '../data/shards_new/shard-000089.tar', '../data/shards_new/shard-000059.tar', '../data/shards_new/shard-000002.tar', '../data/shards_new/shard-000056.tar', '../data/shards_new/shard-000096.tar', '../data/shards_new/shard-000025.tar', '../data/shards_new/shard-000018.tar', '../data/shards_new/shard-000033.tar', '../data/shards_new/shard-000019.tar', '../data/shards_new/shard-000079.tar', '../data/shards_new/shard-000014.tar', '../data/shards_new/shard-000039.tar', '../data/shards_new/shard-000075.tar', '../data/shards_new/shard-000066.tar', '../data/shards_new/shard-000094.tar', '../data/shards_new/shard-000077.tar', '../data/shards_new/shard-000011.tar', '../data/shards_new/shard-000028.tar', '../data/shards_new/shard-000091.tar', '../data/shards_new/shard-000064.tar', '../data/shards_new/shard-000008.tar', '../data/shards_new/shard-000030.tar', '../data/shards_new/shard-000007.tar', '../data/shards_new/shard-000043.tar', '../data/shards_new/shard-000005.tar', '../data/shards_new/shard-000092.tar', '../data/shards_new/shard-000024.tar', '../data/shards_new/shard-000053.tar', '../data/shards_new/shard-000029.tar', '../data/shards_new/shard-000074.tar', '../data/shards_new/shard-000073.tar', '../data/shards_new/shard-000001.tar', '../data/shards_new/shard-000038.tar', '../data/shards_new/shard-000027.tar', '../data/shards_new/shard-000068.tar', '../data/shards_new/shard-000052.tar', '../data/shards_new/shard-000088.tar', '../data/shards_new/shard-000093.tar', '../data/shards_new/shard-000021.tar', '../data/shards_new/shard-000015.tar', '../data/shards_new/shard-000016.tar', '../data/shards_new/shard-000054.tar', '../data/shards_new/shard-000049.tar', '../data/shards_new/shard-000026.tar']\n"
     ]
    }
   ],
   "source": [
    "urls = [os.path.join(shards_dir, it) for it in os.listdir(shards_dir) if it.endswith('.tar')]\n",
    "print(urls)\n",
    "wds_len = len(urls)*shard_size//batch_size\n",
    "\n",
    "image_dataset = (\n",
    "    wds\n",
    "    .WebDataset(urls, length=wds_len)\n",
    "    .shuffle(shard_size)\n",
    "    .decode('torch')\n",
    "    .to_tuple('volumes.pyd', 'labels.pyd', 'studynames.pyd')\n",
    "    .batched(batch_size)\n",
    "#     .map_tuple(pre_transforms, identity, identity)\n",
    ")\n",
    "\n",
    "\n",
    "image_loader = torch.utils.data.DataLoader(image_dataset, num_workers=0, batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AwUtipxTGNQq"
   },
   "source": [
    "### 1. Load an image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622616593423,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "iIdnH_AVGNQr"
   },
   "outputs": [],
   "source": [
    "# patient_num = 1\n",
    "\n",
    "# for t, (x, y, z) in enumerate(image_loader):\n",
    "#     if t > 0:\n",
    "#         break\n",
    "#     img_df = x[patient_num, :, :, :].detach().numpy()\n",
    "#     img_y = y[patient_num, :]\n",
    "# del x # For now for memory reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622616593424,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "NAfZ9dTCGNQr"
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(5,8, figsize=(15, 6))\n",
    "# axs = axs.ravel()\n",
    "# for i in range(40):\n",
    "#     axs[i].imshow(img_df[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtSeabbvGNQs"
   },
   "source": [
    "### 2. Load a pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11416,
     "status": "ok",
     "timestamp": 1622616604833,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "_QMU0BvsGNQs",
    "outputId": "dfb40c38-8b90-469a-c427-9d60b9761ab7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_dir = os.path.join('..', 'runs', 'baseline')\n",
    "# ckpt_path = os.path.join(ckpt_dir, 'Checkpoints', 'ep_5_iter_65_ckpt.pt')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'baseline_final_model.pt') # COLAB\n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "ckpt_model = baseline_3DCNN(in_num_ch=1)\n",
    "ckpt_model.load_state_dict(ckpt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8Vb5EQqMKvc"
   },
   "source": [
    "### 3. Saliency map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1622616622945,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "_Bw8x2W9iTpS",
    "outputId": "eb09eb16-c224-4e0c-bba7-35fbb74a0eac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "#     dtype = torch.cuda.FloatTensor\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = os.path.join('..', 'net_visualization')\n",
    "full_sal_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 23975,
     "status": "error",
     "timestamp": 1622618523806,
     "user": {
      "displayName": "Jong Ha Lee",
      "photoUrl": "",
      "userId": "00384829411400968083"
     },
     "user_tz": 420
    },
    "id": "SpD_zYtuMMxA",
    "outputId": "8ca56328-b912-4bd4-8c69-af0e7c1bc409"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 0:   0%|          | 0/384 [00:13<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e7f47fa68d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Compute whether prediction was correct or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# N X 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# N X 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "with tqdm(image_loader, unit=\"batch\") as tepoch:\n",
    "    for t, (x, y, z) in enumerate(tepoch): # For each batch\n",
    "        if t>0:\n",
    "            break\n",
    "        tepoch.set_description(\"Batch %d\" % t)\n",
    "        \n",
    "        # Some default constants\n",
    "        N = y.shape[0]\n",
    "        ICHD = y.shape[1]\n",
    "\n",
    "        # Compute saliency and rank of slices\n",
    "        saliency = compute_saliency_maps(x, y, ckpt_model, device) # (ICH_types, N, D, H, W)\n",
    "        saliency_rank = rank_saliency_slices(saliency) #(ICH_types, N, D)\n",
    "\n",
    "        # Compute whether prediction was correct or not\n",
    "        ckpt_model = ckpt_model.to(device)\n",
    "        # x = x.to(device, dtype=torch.float)\n",
    "        # y = y.to(device, dtype=torch.float)\n",
    "        scores = ckpt_model(x.to(device, dtype=torch.float)) # N X 6\n",
    "        probs = torch.sigmoid(scores) # N X 6\n",
    "\n",
    "        preds = (probs >= 0.5).long()\n",
    "        corr_bool = (y == preds.cpu()).long() # N X 6\n",
    "\n",
    "        # Save plot of saliency map in each patient directory\n",
    "        for p_index in range(N):\n",
    "            patient_id = z[p_index].item()\n",
    "            patient_ichs_ind = y[p_index, :].nonzero(as_tuple=True)[0] # Only ICH nums which patients have\n",
    "            patient_corr = corr_bool[p_index, :]\n",
    "\n",
    "            # Make plot directory for patient\n",
    "            dir_nm = '_'.join([patient_id, \n",
    "                               'numICHs', str(len(patient_ichs_ind)), \n",
    "                               'numCorr', str(patient_corr[patient_ichs_ind].sum().item())\n",
    "                              ])\n",
    "            patient_dir = os.path.join(plot_dir, dir_nm)\n",
    "            os.mkdir(patient_dir)\n",
    "\n",
    "            for ich_num in patient_ichs_ind.cpu().numpy():\n",
    "                sal_plot = plot_saliency_maps(x, saliency, ich_num=ich_num, patient_id=p_index, d_range=np.arange(0,40))\n",
    "                sal_plot.savefig(os.path.join(patient_dir, '_'.join(['ICHNum', str(ich_num), 'Corr', str(patient_corr[ich_num].item())])))\n",
    "                plt.close(sal_plot)\n",
    "\n",
    "        # Convert to pandas df to save general information (patient ID, num of ICH class, pred corr or not (per num ICH class), sal rank per ICH class)\n",
    "        save_df = pd.DataFrame(saliency_rank.cpu().numpy().reshape(ICHD*N, -1)) # (ICH_types*N, D)\n",
    "        save_df.columns = ['rank_' + str(rk) for rk in save_df.columns]\n",
    "\n",
    "        save_df['patient_id'] = z.repeat(ICHD)\n",
    "        save_df['ICH_num'] = np.tile(np.arange(0, ICHD), N)\n",
    "        save_df['ICH_true'] = y.numpy().astype(int).reshape(-1)\n",
    "        save_df['ICH_pred'] = preds.cpu().numpy().astype(int).reshape(-1)\n",
    "        save_df['corr_pred'] = corr_bool.numpy().reshape(-1)\n",
    "        save_df = save_df[save_df.columns.tolist()[-5:] + save_df.columns.tolist()[:-5]]\n",
    "\n",
    "        full_sal_df = pd.concat([full_sal_df, save_df], axis=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SoX3BJh3q05"
   },
   "outputs": [],
   "source": [
    "# Getting which patients have non ICH types\n",
    "patient_keys, nonzero_dims = y.nonzero(as_tuple=True)\n",
    "patient_keys = list(patient_keys.numpy())\n",
    "nonzero_dims = list(nonzero_dims.numpy())\n",
    "\n",
    "nonzero_dict = {}\n",
    "for i in range(len(patient_keys)):\n",
    "    nonzero_dict[patient_keys[i]] = nonzero_dict.get(patient_keys[i], []) + [nonzero_dims[i]]\n",
    "nonzero_dict"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "visualize_saliency_with_backprop.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
